[strings]
# Mode : train, test, serve
mode = train
seq_data = train_data/seq.data
train_data=train_data

resource_data = train_data/new.conv

e = E
m = M

model_data = model_data
[ints]
# vocabulary size 
# 	20,000 is a reasonable size
enc_vocab_size = 20000
dec_vocab_size = 20000
embedding_dim=128

# typical options : 128, 256, 512, 1024
layer_size = 256
# dataset size limit; typically none : no limit
max_train_data_size = 50000
batch_size = 128


